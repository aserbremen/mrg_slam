# ROS2 mrg_slam package

This repository contains the source code of the `mrg_slam` package for the [Multi-Robot-Graph-SLAM](https://github.com/aserbremen/Multi-Robot-Graph-SLAM) repository. 
## Table of Contents

- [ROS2 mrg\_slam package](#ros2-mrg_slam-package)
  - [Table of Contents](#table-of-contents)
  - [General Information](#general-information)
  - [Prefiltering Component](#prefiltering-component)
    - [Prefiltering Inputs and Outputs](#prefiltering-inputs-and-outputs)
    - [Prefiltering Parameters](#prefiltering-parameters)
  - [Scan Matching Odometry Component](#scan-matching-odometry-component)
    - [Scan Matching Odometry Parameters](#scan-matching-odometry-parameters)
  - [Floor Detection Component](#floor-detection-component)
    - [Floor Detection Parameters](#floor-detection-parameters)
  - [Multi-Robot-Graph-SLAM Component](#multi-robot-graph-slam-component)

## General Information
This package contains 4 ROS2 components, see `apps` folder:
- [prefiltering_component](apps/prefiltering_component.cpp)
- [scan_matching_odometry_component](apps/scan_matching_odometry_component.cpp)
- [floor_detection_component](apps/floor_detection_component.cpp)
- [mrg_slam_component](apps/mrg_slam_component.cpp)

For running the SLAM only using LIDAR data, the `prefiltering_component`, `scan_matching_odometry_component`, and `mrg_slam_component` are required. 
The `floor_detection_component` is optional and can be used to improve the SLAM performance, when there is a distinct floor in the environment.

This readme file contains information about inputs/outputs and parameters of the components to the best of my knowledge. This package is a port and multi-robot extension of the ROS1 [hdl_graph_slam](https://github.com/koide3/hdl_graph_slam) package which includes a lot of functionality. So far only a subset of the functionality has been relevant to me, that's why I have not tested all the functionality of the package.
Disclaimer :information_source:: Parts of this README are generated by an AI, however I have reviewed it to the best of my knowledge. 
Disclaimer :information_source:: If you have tested any functionality that I disclaim to be untested, please let me know and I will update the readme file accordingly.

Here are some things to consider when using the `mrg_slam` package:

- The launch file [mrg_slam.launch.py](launch/mrg_slam.launch.py) launches all the components required for the SLAM in a component container with intraprocess communication enabled. Plus additional nodes that are required for the SLAM to work.
- Command line arguments can be used in conjunction with the launch file to set certain parameters, such as the robot name and the initial pose of the robot.
  - The `PARAM_MAPPING` dictionary in the launch file maps the command line arguments to the parameters of the components and overwrites if they are given as command line arguments. You can remove and add parameters to the dictionary as needed.
  - All kinds of topics and services are remapped in the launch file to consider the `model_namespace` aka the robot name.
- The only required message for the SLAM to work is the `sensor_msgs/msg/PointCloud2` message with the topic `/model_namepsace/velodyne_points`. The `model_namespace` is the name of the robot, which is used to distinguish between the different robots in the system. The `frame_id` of the point cloud message should be `model_namespace/velodyne`. 
- All robot names participating in the multi-robot SLAM should be given in the `multi_robot_names` parameter in the used configuration file. Otherwise the different SLAM instances won't exchange keyframes and edges between them.
  - You can use the SLAM without a `model_namespace` by setting the `model_namespace` parameter to an empty string in the configuration file. This is useful when the robot uses hard-coded frames such as `odom` or `base_link`.
  - You can also insert an empty string "" into the `multi_robot_names` parameter in the configuration file to use the SLAM without a `model_namespace` in a multi-robot scenario.
- Most nodes in the `mrg_slam.yaml` can be enabled/disabled by setting the respective parameter to `true`/`false` for testing certain parts of the SLAM system.

- Check out the [mrg_slam_velodyne_VLP16.yaml](config/mrg_slam_velodyne_VLP16.yaml) file for an example configuration file for the SLAM using live data from a Velodyne VLP-16 LIDAR sensor. `use_sim_time` is set to `false` and `velodyne/ros__parameters/enable_velodyne` is set to true in this configuration file.
  - We launch the velodyne driver node and the transform node ourselves in the launch file, because we want the `frame_id` in the point cloud message to be `model_namespace/velodyne`. The `frame_id` in the point cloud message is set to `velodyne` by default in the velodyne driver node and cannot be changed easily.
  - Also we don't need the laser scan message which is published by the velodyne driver standard launch file. We only need the point cloud message.

## Prefiltering Component

The `prefiltering_component` is used to filter the point cloud data before it is used for the SLAM.

### Prefiltering Subscriptions and Publishers

- The following inputs and outputs are the default topics. 
- `model_namespace` is left out in the topics of the following

| Inputs | Type | Information |
|--------|---------|-----------|
| `velodyne_points`  | `sensor_msgs/msg/PointCloud2` | **Required**: The point cloud data from the LIDAR sensor. The `frame_id` of the point cloud message should be `model_namespace/velodyne`. |
| `imu_topic` | `sensor_msgs/msg/Imu` | **Optional**: The IMU data from the robot. Can be used for the IMU frontend and  `deskewing` of the point cloud data. |

| Outputs | Type | Information |
|---------|---------|-----------|
| `prefiltering/filtered_points` | `sensor_msgs/msg/PointCloud2` | The filtered point cloud data. The `model_namespace` is the name of the robot. |
| `prefiltering/colored_points` | `sensor_msgs/msg/PointCloud2` | The color encodes the point number in the point cloud. |

### Prefiltering Parameters

| Parameter Name       | Description                                                                 |
|----------------------|-----------------------------------------------------------------------------|
| `enable_prefiltering` | If true, the `prefiltering_component` is launched.                        |
| `downsample_method`  | Specifies the method used for downsampling the point cloud data. Options are [`VOXELGRID`, `APPROX_VOXELGRID`, `NONE`].<br> `VOXELGRID`: downsamples a point cloud by dividing the space into a 3D grid of equally-sized cubes (voxels) and replacing all the points inside each voxel with a single representative point (usually the centroid).<br> `APPROX_VOXELGRID`: very similar to VoxelGrid, but it uses a faster approximation algorithm. Trades speed for accuracy. <br> `NONE`: No downsampling is performed. |
| `downsample_resolution` | Specifies the resolution for downsampling the point cloud data. Higher values reduce computational load and thin out the cloud more. |
| `outlier_removal_method` | Specifies the method used for outlier removal. Options are [`STATISTICAL`, `RADIUS`, `NONE`]. <br>`STATISTICAL`: `pcl::StatisticalOutlierRemoval`, the distance and its standard deviation of point to `k` of its neigbors are used to remove outliers. <br> `RADIUS`: `pcl::RadiusOutlierRemoval`, a radius search is performed to find the neighbors of each point.<br> `NONE`: No outlier removal is performed. |
| `statistical_mean_k` | `STATISTICAL`: The number of nearest neighbors to use when computing the mean distance from each point to its neighbors. Higher values lead to a more stable and smoother estimate of what constitutes a "normal" neighborhood — better for dense clouds. Lower values make the filter more sensitive to local variations — might preserve more detail but also more noise. |
| `statistical_stddev` | `STATISTICAL`: The threshold multiplier of the standard deviation to determine whether a point is an outlier. A point is considered an outlier if its average distance to its neighbors is larger than the global mean distance + stddev_mul_thresh * standard deviation. |
| `radius_radius` | `RADIUS`: The radius of the sphere to search for neighbors. |
| `radius_min_neighbors` | `RADIUS`: The minimum number of neighbors required to consider a point as an inlier. |
| `use_distance_filter` | If true, the distance filter is applied to the point cloud data. The distance filter removes points that are too close or too far from the robot. |
| `distance_near_thresh` | The minimum distance from the robot to keep points. Points closer than this distance are removed. If your LIDAR hits part of the robot it is beneficial to set this value to a value larger than the radius of the robot. |
| `distance_far_thresh` | The maximum distance from the robot to keep points. Points farther than this distance are removed. If you want a higher quality map for trading off range, you can set this value to a lower value. E.g. house walls will align better across keyframes if you set this value to 20m instead of 50m. |
| `scan_period` | The time between two scans. This is used in the `deskewing` method to determine the time between two scans. |
| `deskewing` | If true, the point cloud data is deskewed. Deskewing is the process of correcting the point cloud data for the motion of the robot during the scan. This is useful when the robot is moving fast or the LIDAR exhibits a large amount of motion. |
| `base_link_frame` | The frame of the robot that is used to transform the point cloud data. This is usually the `base_link` frame of the robot. The `base_link_frame` is prepended with the `model_namespace` to get the full frame name. |

Disclaimer :information_source:: The `deskewing` method is not tested yet. If anyone has, let me know.

## Scan Matching Odometry Component

The `scan_matching_odometry_component` is used to estimate the odometry of the robot using the point cloud data. The component subscribes to the `/model_namespace/prefiltering/filtered_points` topic and publishes the odometry data on the `/model_namespace/scan_matching_odometry/odom` topic.
Odometry through scan matching is susceptible to drift over time. 
:information_sourece: The `enable_imu_frontend` parameter is not tested in the ROS2 version of the package. This could potentially be used to reduce the drift in the odometry data by using the IMU data of the robot.

### Scan Matching Odometry Subscriptions and Publishers

| Inputs | Type | Information |
|--------|---------|-----------|
| `prefiltering/filtered_points`  | `sensor_msgs/msg/PointCloud2` | **Required**: The filtered point cloud data from the prefiltering component. The `model_namespace` is prepended to the topic name. |
| `msf_core/pose` | `geometry_msgs/msg/PoseWithCovarianceStamped` | **Optional**: Pose estimate used when `enable_imu_frontend` is set to true. |
| tf listener | `tf2_ros::Buffer` | Used when `enable_robot_odometry_init_guess` is set to true. |

| Outputs | Type | Information |
|---------|---------|-----------|
| `scan_matching_odometry/odom` | `nav_msgs/msg/Odometry` | The odometry data from the scan matching odometry component. |
| `scan_matching_odometry/transform`| `geometry_msgs/msg/TransformStamped` | The transform data from the scan matching odometry component. |
| `scan_matching_odometry/status` | `mrg_slam_msgs/msg/ScanMatchingStatus` | Contains additional information about the scan matching odometry. |
| `scan_matching_odometry/aligned_points` | `sensor_msgs/msg/PointCloud2` | The aligned point cloud data from the scan matching odometry component. |
| baselink to odom | `tf2_ros::TransformBroadcaster` | The transform between the `base_link` frame and the `odom` frame. The `model_namespace` is prepended to the frame name. |
| baselink to keyframe | `tf2_ros::TransformBroadcaster` | The transform between the `base_link` frame and the `keyframe` frame. The keyframe is set when the `keyframe_delta_trans` or `keyframe_delta_angle` parameters are exceeded. |


### Scan Matching Odometry Parameters

| Parameter Name | Description |
|----------------|-------------|
| `enable_scan_matching_odometry` | If true, the `scan_matching_odometry_component` is launched. |
| `enable_odom_to_file` | If true, the odometry data is saved to a file. A separate `odom_to_file.py` executable is used to save the odometry data to a file. Default `result_file` parameter is set to `'/tmp/' + model_namespace + '_scan_matching_odom.txt'`. |
| `points_topic` | The topic of the point cloud data. The `model_namespace` is prepended to the topic name. |
| `odom_frame_id` | The frame of the odometry data. The `model_namespace` is prepended to the frame name. |
| `enable_robot_odometry_init_guess` | If true, the tf tree is queried to get the initial guess of the robot odometry between the point cloud's `frame_id` and the `robot_odom_frame_id`. Disclaimer :information_source:: The `enable_robot_odometry_init_guess` parameter is not tested yet. |
| `robot_odom_frame_id` | The frame of the robot odometry data. The `model_namespace` is prepended to the frame name. Used when `enable_robot_odometry_init_guess` is set to true. | 
| `keyframe_delta_trans` | The maximum translation distance threshold until the input point cloud/target of the scan matching algorithm is updated. |
| `keyframe_delta_angle` | The maximum rotation angle threshold until the input point cloud/target of the scan matching algorithm is updated. |
| `keyframe_delta_time` | The maximum time until the input point cloud/target of the scan matching algorithm is updated. |
| `transform_thresholding` | If true, the transformation (translation and rotation) of the scan matching algorithm is thresholded against `max_acceptable_trans` and `max_acceptable_angle` parameters. |
| `max_acceptable_trans` | The maximum allowed translation distance of the scan matching algorithm. If the translation distance is larger than this value, the previous scan matching result is used. |
| `max_acceptable_angle` | The maximum rotation angle of the scan matching algorithm. If the rotation angle is larger than this value, the previous scan matching result is used. |
| `enable_imu_frontend` | If true, the IMU data is used to improve the scan matching odometry. Disclaimer :information_source:: The IMU frontend is not tested yet. |
| `downsample_method` | Specifies the method used for downsampling the point cloud data. This is helpful when you want to downsize the point cloud independent or additionally to the `prefiltering_component` for scan matching. Options are [`VOXELGRID`, `APPROX_VOXELGRID`, `NONE`].<br> `VOXELGRID`: downsamples a point cloud by dividing the space into a 3D grid of equally-sized cubes (voxels) and replacing all the points inside each voxel with a single representative point (usually the centroid).<br> `APPROX_VOXELGRID`: very similar to VoxelGrid, but it uses a faster approximation algorithm. Trades speed for accuracy. <br> `NONE`: No downsampling is performed. |
| `downsample_resolution` | Specifies the resolution for downsampling the point cloud data. Higher values reduce computational load and thin out the cloud more. |
| `registration_method` | Specifies the method used for point cloud registration aka scan matching. Options are [`ICP`, `GICP`, `NDT`, `GICP_OMP`, `FAST_GICP`, `FAST_VGICP`, `SMALL_GICP` (recommended)]. <br>`ICP`: Iterative Closest Point, a classic method for point cloud registration. Disclaimer :information_source:: The `ICP` method is not tested yet. <br> `GICP`: Generalized Iterative Closest Point, a more advanced method for point cloud registration. Disclaimer :information_source:: The `GICP` method is not tested yet. <br> `NDT`: Normal Distributions Transform, a probabilistic method for point cloud registration. <br> `GICP_OMP`: Generalized Iterative Closest Point with OpenMP support, a more advanced method for point cloud registration. Disclaimer :information_source:: The `GICP_OMP` method is not tested yet. <br> `FAST_GICP`: A faster version of the GICP method. <br> `FAST_VGICP`: A faster version of the VGICP method. <br> `SMALL_GICP`: The successor of `FAST_GICP`. |
| `reg_num_threads` | The number of threads to use for the registration method. This is useful when your registration method supports multithreading. |
| `reg_transformation_epsilon` | The transformation epsilon (maximum allowable translation squared difference between two consecutive transformations) in order for an optimization to be considered as having converged to the final solution. |
| `reg_maximum_iterations` | The maximum number of iterations for the registration method optimization, outer loop. |
| `reg_max_optimizer_iterations` | The maximum number of iterations for one optimization step, inner loop. |
| `reg_max_correspondence_distance` | The maximum distance threshold between two correspondent points in source <-> target. If the distance is larger than this threshold, the points will be ignored in the alignment process. |
| `reg_use_reciprocal_correspondences` | If true, the reciprocal correspondences for point matches are used for the registration method (source to target and target to source correspondence). This is useful when the point clouds noisy and only partial overlap. |
| `reg_correspondence_randomness` | The number of random correspondences for covariance estimation. |
| `reg_resolution` | The resolution of the voxel grid for the registration method, relevant for `FAST_VGICP_CUDA`, `VGICP_CUDA` and `NDT`. | 
| `reg_nn_search_method` | Neighborhood search method for `NDT`, options are [`KDTREE`, `DIRECT1`, `DIRECT7`] |

## Floor Detection Component

The `floor_detection_component` is used to detect the floor in the point cloud data. The component subscribes to the `/model_namespace/prefiltering/filtered_points` topic and publishes plane coefficients on the topic `/model_namespace/floor_detection/floor_coeffs`. 
In structured environments, the floor detection might improve the SLAM performance. 

### Floor Detection Parameters

| Parameter Name | Description |
|----------------|-------------|
| `enable_floor_detection` | If true, the `floor_detection_component` is launched. |
| `tilt_deg` | Approximate tilt/pitch angle of the LIDAR sensor in degrees. The cloud is rotated accordingly. |
| `sensor_height` | Sensor height in meters used to filter points and only keep points in the range of the `sensor_height` +- `height_clip_range`. | 
| `height_clip_range` | The range around the `sensor_height` to keep points. |
| `floor_pts_thresh` | Minimum number of points to perform RANSAC plane fitting and mininum number of RANSAC inlier points to publish the plane coefficients. |
| `floor_normal_thresh` | The maximum allowed angle in degrees between the normal vector of the plane and the vertical axis. |
| `use_normal_filtering` | If true, points with "non-"vertical normals will be filtered before RANSAC |
| `normal_filter_thresh` | The maximum allowed angle in degrees between the normal vector of the point and the vertical axis. |


## Multi-Robot-Graph-SLAM Component

- The `mrg_slam_component` is used to perform the SLAM using the odometry data from the `scan_matching_odometry_component`. The component subscribes to the `/model_namespace/scan_matching_odometry/odom` and `/model_namespace/prefiltering/filtered_points` topics.
- Depending `keyframe_delta_trans` and `keyframe_delta_angle` parameters, the component decides when to add a new keyframe to the graph. 
- The graph is updated at `graph_update_interval` parameter.
- When using multiple robots, the initial poses of all robots should be set w.r.t. the same global frame.
  - For convenience, you can use the `init_odom_topic` parameter to set the initial pose of the robot using odometry messages (`nav_msgs::msg::Odometry`). Alternatively, you can set the `init_pose_topic` parameter to set the initial pose of the robot using pose messages (`geometry_msgs::msg::PoseStamped`). If you use any of these topics for multiple robots, make sure that the poses are given w.r.t. the same frame. 
  - The initial poses of the robots can also be set using the `x`, `y`, `z` (in meters) and `roll`, `pitch`, and `yaw` (in radians) parameters in the configuration file. Alternatively, the initial pose can be set using the command line arguments.
  - You can use any of the above methods to set the initial pose of the robot, where `init_odom_topic` has the highest priority, followed by `init_pose_topic`, and then the `x`, `y`, `z`, `roll`, `pitch`, and `yaw` parameters. `ros2 launch mrg_slam mrg_slam.launch.py init_odom_topic:=/robot1/odom`, or `ros2 launch mrg_slam mrg_slam.launch.py init_pose_topic:=/robot1/pose`, or `ros2 launch mrg_slam mrg_slam.launch.py x:=0 y:=0 z:=0 roll:=0 pitch:=0 yaw:=0` can be used to set the initial pose of the robot using the command line arguments.
  - Each robot performs SLAM in its own local frame. We enable a static transform broadcaster `map2robotmap_publisher` node to publish the transform between the global frame `map` and the local frame of the robot `model_namespace/map`. This way the maps of all robots can be visualized in the global frame rviz2. You can check the tf tree with `ros2 run rqt_tf_tree rqt_tf_tree`. 

### Multi-Robot-Graph-SLAM Subscriptions and Publishers

| Inputs | Type | Information |
|--------|---------|-----------|
| `scan_matching_odometry/odom`  | `nav_msgs/msg/Odometry` | **Required**: The odometry data from the scan matching odometry component. The odometry is synced with the point cloud data using `message_filters`. |
| `prefiltering/filtered_points` | `sensor_msgs/msg/PointCloud2` | **Required**: The filtered point cloud data from the prefiltering component. The point cloud data is synced with the odometry data using `message_filters`. |
| `/mrg_slam/odom_broadcast` | `mrg_slam_msgs/msg/PoseWithName` | **Required**: The odometry data from the all robots in the system. This information is used to filter out points where other robots are estimated to be. This is a broadcast topic, note the absolute topic name. |
| `/mrg_slam/slam_pose_broadcast` | `mrg_slam_msgs/msg/PoseWithName` | **Required**: The SLAM pose data from the all robots in the system. This pose contains loop closures and graph optimization. The latest SLAM pose plus the delta odometry pose is used to filter out points where other robots are estimated to be. This is a broadcast topic, note the absolute topic name. |
| `init_odom_topic` | `nav_msgs/msg/Odometry` | **Optional**: An odometry message used to set the initial pose of the robot. The pose should be given w.r.t. the global map frame for the multi robot SLAM. The `frame_id` is neglected. Has a higher priority than `init_pose_topic`. |
| `init_pose_topic` | `geometry_msgs/msg/PoseStamped` | **Optional**: A pose message used to set the initial pose of the robot. The pose should be given w.r.t. the global map frame for the multi robot SLAM. The `frame_id` is neglected. |


| Outputs | Type | Information |
|---------|---------|-----------|
| `/mrg_slam/odom_broadcast` | `mrg_slam_msgs/msg/PoseWithName` | **Required**: The odometry data from the all robots in the system. This information is used to filter out points where other robots are estimated to be. This is a broadcast topic, note the absolute topic name. |
| `/mrg_slam/slam_pose_broadcast` | `mrg_slam_msgs/msg/PoseWithName` | **Required**: The SLAM pose data from the all robots in the system. This pose contains loop closures and graph optimization. The latest SLAM pose plus the delta odometry pose is used to filter out points where other robots are estimated to be. This is a broadcast topic, note the absolute topic name. |
| `mrg_slam/odom2map` | `geometry_msgs/msg/TransformStamped` | The transform between the `odom` frame and the `map` frame. |
| `mrg_slam/map_points` | `sensor_msgs/msg/PointCloud2` | The point cloud data of the map published based on a timer. |
| `mrg_slam/map_points_service` | `sensor_msgs/msg/PointCloud2` | The point cloud data of the map published via `mrg_slam/publish_map` service. |
| `mrg_slam/others_poses` | `mrg_slam_msgs/msg/PoseWithNameArray` | The poses of the other robots in the system w.r.t. the own robot. |
| `mrg_slam/other_robots_removed_points` | `sensor_msgs/msg/PointCloud2` | The point cloud containing points where other robots participating in the SLAM are estimated to be. |
| `mrg_slam/slam_status` | `mrg_slam_msgs/msg/SlamStatus` |  Convenience message to check the status of the SLAM, whether it is initialized or in optimization. |


### Multi-Robot-Graph-SLAM Parameters

| Parameter Name | Description |
|----------------|-------------|
| `enable_mrg_slam` | If true, the `mrg_slam_component` is launched. |
| `own_name` | The name of the robot. This is used to distinguish between the different robots in the multi-robot SLAM. |
| `multi_robot_names` | The names of the other robots in the system. If the robot is not in this list, the graph information between missing robots will not be exchanged. Can include an empty string "" for using the SLAM without a `model_namespace`. |
| `robot_remove_points_radius` | The radius around the robot to remove points where other robots are estimated to be. |
| `x` | The initial x position of the robot in meters. |
| `y` | The initial y position of the robot in meters. |
| `z` | The initial z position of the robot in meters. |
| `roll` | The initial roll angle of the robot in radians. |
| `pitch` | The initial pitch angle of the robot in radians. |
| `yaw` | The initial yaw angle of the robot in radians. |
| `init_pose` | The initial pose of the robot in meters and radians (x, y, z, roll, pitch, yaw). The values above are convenience parameters to set this vector. |
| `init_odom_topic` | The topic of the odometry data used to set the initial pose of the robot. The `frame_id` is neglected. Has a higher priority than `init_pose_topic`. |
| `init_pose_topic` | The topic of the pose data used to set the initial pose of the robot. The `frame_id` is neglected. |
| `map_frame_id` | The frame of the map data. |
| `odom_frame_id` | The frame of the odometry data. |
| `odom_sub_topic` | The topic of the odometry data. **TODO**: Check whether manually setting this topic is necessary or not. |
| `cloud_sub_topic` | The topic of the point cloud data. **TODO**: Check whether manually setting this topic is necessary or not. |
| `g2o_solver_type` | The type of solver used for the graph optimization. Typical solvers are [`gn_var`, `gn_fix6_3`, `gn_var_cholmod`, `lm_var`, `lm_fix6_3`, `lm_var_cholmod`, ...] |
| `g2o_solver_num_iterations` | The number of iterations for the graph optimization. |
| `g2o_verbose` | If true, the graph optimization is verbose. |
| `enable_gps` | If true, the GPS data is used in the SLAM. |
| `enable_imu_acceleration` | If true, a prior edge is added to the graph using the IMU acceleration data. |
| `enable_imu_orientation` | If true, a prior edge is added to the graph using the IMU orientation data. |